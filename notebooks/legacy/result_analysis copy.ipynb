{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "02a614ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "try:\n",
    "    import pyvips  # type: ignore\n",
    "    _HAS_PYVIPS = True\n",
    "except Exception:\n",
    "    pyvips = None\n",
    "    _HAS_PYVIPS = False\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/users/ntu/lizh0106/scratch/nscc_work/Baseline_models\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "#sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from src.config import load_paths, load_params\n",
    "from src.data.features import prepare_features\n",
    "from src.models.train import cross_validate, predict_external\n",
    "from src.evaluation.grading import gleason_to_isup\n",
    "from src.evaluation.metrics import evaluate_slide_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c83c59",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "80b4dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path =Path(\"results/hard_labels\")\n",
    "\n",
    "# ===================================\n",
    "test_folder = \"XGB_nol2_with2048\" # 需要和base_path链接，里面有aggc_prob_p 和tcga_prob_p\n",
    "\n",
    "df_aggc_index = \"/home/users/ntu/lizh0106/scratch/nscc_work/Processed_Features/AGGC/20x_512/index.csv\"\n",
    "df_tcga_index = \"/home/users/ntu/lizh0106/scratch/nscc_work/Processed_Features/TGGA_PRAD_V2/TGGA_PRAD_V2_without_anno/TCGA_20x512/index.csv\"\n",
    "\n",
    "aggc_prob_p = \"aggc_oof_tile_proba.npy\"\n",
    "tcga_prob_p = \"tcga_proba_mean.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ba44616",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN_MAP = {0: 3, 1: 4, 2: 5}\n",
    "# def gleason_to_isup(g1, g2): ...\n",
    "\n",
    "def agg_from_tiles(\n",
    "    df_index: pd.DataFrame,\n",
    "    tile_predictions: np.ndarray,\n",
    "    pattern_map=None,\n",
    "    primary_thresh: float = 0.95,\n",
    "    secondary_min: float = 0.05,\n",
    "    agg_input: str = \"proba\",\n",
    "    # --- 新增：高置信聚合控制 ---\n",
    "    conf_mode: str = \"none\",        # \"none\" | \"topk\" | \"threshold\" | \"weight\"\n",
    "    top_frac: float = 0.3,          # topk: 取 top 30%\n",
    "    conf_threshold: float = 0.7,    # threshold: 置信度阈值\n",
    "    min_tiles: int = 5,            # 筛选后少于这个数 -> fallback\n",
    "    weight_power: float = 1.0,      # weight: w = conf^power\n",
    "    conf_use_classes: int = 3,      # 只用前3类(tumor patterns)计算置信度\n",
    "):\n",
    "    \"\"\"\n",
    "    Aggregate tile-level class predictions to slide-level Gleason/ISUP.\n",
    "\n",
    "    High-confidence aggregation (proba mode only):\n",
    "      - conf_mode=\"topk\": keep top_frac of tiles by confidence\n",
    "      - conf_mode=\"threshold\": keep tiles with confidence >= conf_threshold\n",
    "      - conf_mode=\"weight\": use all tiles, weight each tile by confidence^weight_power\n",
    "      - conf_mode=\"none\": no filtering/weighting (your original behavior)\n",
    "    \"\"\"\n",
    "    if pattern_map is None:\n",
    "        pattern_map = PATTERN_MAP\n",
    "\n",
    "    if agg_input not in {\"labels\", \"proba\"}:\n",
    "        raise ValueError(\"agg_input must be either 'labels' or 'proba'.\")\n",
    "\n",
    "    if conf_mode not in {\"none\", \"topk\", \"threshold\", \"weight\"}:\n",
    "        raise ValueError(\"conf_mode must be one of: none, topk, threshold, weight\")\n",
    "\n",
    "    out_rows = []\n",
    "    for _, row in df_index.iterrows():\n",
    "        slide_id = row[\"slide_id\"]\n",
    "        start = int(row[\"start\"])\n",
    "        end = start + int(row[\"length\"])\n",
    "\n",
    "        tiles_preds = tile_predictions[start:end]\n",
    "\n",
    "        if agg_input == \"labels\":\n",
    "            # 原逻辑：硬标签计数\n",
    "            counts = np.bincount(tiles_preds, minlength=4)\n",
    "            tumor_scores = counts[:3].astype(float)\n",
    "\n",
    "        else:\n",
    "            # 原逻辑：proba 汇总（增强：可筛选/加权）\n",
    "            if tiles_preds.ndim != 2 or tiles_preds.shape[1] < 3:\n",
    "                raise ValueError(\n",
    "                    \"For agg_input='proba', tile_predictions must have shape (n_tiles, n_classes>=3).\"\n",
    "                )\n",
    "\n",
    "            proba = tiles_preds[:, :3].astype(float)  # 只取 G3/G4/G5\n",
    "\n",
    "            # 置信度：只在 tumor 三类内部取 max（避免 other 类干扰）\n",
    "            # 如果你想用 full classes 做置信度，把 conf_use_classes 改成 proba.shape[1] 并传入全 proba\n",
    "            conf = proba[:, :min(conf_use_classes, proba.shape[1])].max(axis=1)\n",
    "\n",
    "            # --- 选择/加权 tile ---\n",
    "            if conf_mode == \"none\":\n",
    "                sel_proba = proba\n",
    "                weights = None\n",
    "\n",
    "            elif conf_mode == \"topk\":\n",
    "                n = len(conf)\n",
    "                k = max(1, int(np.ceil(n * top_frac)))\n",
    "                idx = np.argpartition(conf, -k)[-k:]   # 比 argsort 更快\n",
    "                sel_proba = proba[idx]\n",
    "                weights = None\n",
    "\n",
    "                # fallback：太少就用全体\n",
    "                if sel_proba.shape[0] < min_tiles:\n",
    "                    sel_proba = proba\n",
    "                    weights = None\n",
    "\n",
    "            elif conf_mode == \"threshold\":\n",
    "                idx = np.where(conf >= conf_threshold)[0]\n",
    "                sel_proba = proba[idx]\n",
    "                weights = None\n",
    "\n",
    "                if sel_proba.shape[0] < min_tiles:\n",
    "                    sel_proba = proba\n",
    "                    weights = None\n",
    "\n",
    "            else:  # conf_mode == \"weight\"\n",
    "                # 不删 tile，按置信度加权（最稳）\n",
    "                weights = np.power(conf, weight_power)\n",
    "                # 防止全 0\n",
    "                if np.all(weights == 0):\n",
    "                    weights = None\n",
    "                sel_proba = proba\n",
    "\n",
    "            # --- 聚合 ---\n",
    "            if weights is None:\n",
    "                tumor_scores = sel_proba.sum(axis=0)\n",
    "            else:\n",
    "                tumor_scores = (sel_proba * weights[:, None]).sum(axis=0)\n",
    "\n",
    "        total_tumor = float(tumor_scores.sum())\n",
    "\n",
    "        if total_tumor == 0:\n",
    "            out_rows.append({\n",
    "                \"slide_id\": slide_id,\n",
    "                \"p3\": 0.0, \"p4\": 0.0, \"p5\": 0.0,\n",
    "                \"primary_pattern\": None,\n",
    "                \"secondary_pattern\": None,\n",
    "                \"gleason\": None,\n",
    "                \"ISUP_grade_group\": None,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        p3, p4, p5 = (tumor_scores / total_tumor).tolist()\n",
    "        fractions = np.array([p3, p4, p5], dtype=float)\n",
    "\n",
    "        order = np.argsort(-fractions)\n",
    "        p1_idx, p2_idx = int(order[0]), int(order[1])\n",
    "        p1_frac, p2_frac = float(fractions[p1_idx]), float(fractions[p2_idx])\n",
    "\n",
    "        if p1_frac >= primary_thresh or p2_frac < secondary_min:\n",
    "            g1 = g2 = pattern_map[p1_idx]\n",
    "        else:\n",
    "            g1 = pattern_map[p1_idx]\n",
    "            g2 = pattern_map[p2_idx]\n",
    "\n",
    "        out_rows.append({\n",
    "            \"slide_id\": slide_id,\n",
    "            \"p3\": float(p3),\n",
    "            \"p4\": float(p4),\n",
    "            \"p5\": float(p5),\n",
    "            \"primary_pattern\": g1,\n",
    "            \"secondary_pattern\": g2,\n",
    "            \"gleason\": f\"{g1}+{g2}\",\n",
    "            \"ISUP_grade_group\": gleason_to_isup(g1, g2),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad699ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>y</th>\n",
       "      <th>start</th>\n",
       "      <th>length</th>\n",
       "      <th>n_tiles_read</th>\n",
       "      <th>h5_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subset1_Train_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10339</td>\n",
       "      <td>10339</td>\n",
       "      <td>/home/users/ntu/lizh0106/scratch/nscc_work/AGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subset1_Train_10</td>\n",
       "      <td>3</td>\n",
       "      <td>10339</td>\n",
       "      <td>14579</td>\n",
       "      <td>14579</td>\n",
       "      <td>/home/users/ntu/lizh0106/scratch/nscc_work/AGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subset1_Train_100</td>\n",
       "      <td>3</td>\n",
       "      <td>24918</td>\n",
       "      <td>7562</td>\n",
       "      <td>7562</td>\n",
       "      <td>/home/users/ntu/lizh0106/scratch/nscc_work/AGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subset1_Train_101</td>\n",
       "      <td>1</td>\n",
       "      <td>32480</td>\n",
       "      <td>5704</td>\n",
       "      <td>5704</td>\n",
       "      <td>/home/users/ntu/lizh0106/scratch/nscc_work/AGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subset1_Train_102</td>\n",
       "      <td>2</td>\n",
       "      <td>38184</td>\n",
       "      <td>10464</td>\n",
       "      <td>10464</td>\n",
       "      <td>/home/users/ntu/lizh0106/scratch/nscc_work/AGG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slide_id  y  start  length  n_tiles_read  \\\n",
       "0    Subset1_Train_1  1      0   10339         10339   \n",
       "1   Subset1_Train_10  3  10339   14579         14579   \n",
       "2  Subset1_Train_100  3  24918    7562          7562   \n",
       "3  Subset1_Train_101  1  32480    5704          5704   \n",
       "4  Subset1_Train_102  2  38184   10464         10464   \n",
       "\n",
       "                                             h5_path  \n",
       "0  /home/users/ntu/lizh0106/scratch/nscc_work/AGG...  \n",
       "1  /home/users/ntu/lizh0106/scratch/nscc_work/AGG...  \n",
       "2  /home/users/ntu/lizh0106/scratch/nscc_work/AGG...  \n",
       "3  /home/users/ntu/lizh0106/scratch/nscc_work/AGG...  \n",
       "4  /home/users/ntu/lizh0106/scratch/nscc_work/AGG...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4cdd9a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Slide-level Evaluation ===\n",
      "Slides with NaN predictions: 0 / 187\n",
      "\n",
      "--- Including NaNs (as class 5) ---\n",
      "Accuracy: 0.6256684491978609\n",
      "--- Excluding NaNs ---\n",
      "Accuracy: 0.6256684491978609\n",
      "Balanced accuracy: 0.3787878787878788\n",
      "Confusion matrix:\n",
      " [[ 0  8  3  0  0  0]\n",
      " [ 0 65 12  0  1  0]\n",
      " [ 0 20 43  1  2  0]\n",
      " [ 0  1  3  0  6  0]\n",
      " [ 0  0 13  0  9  0]\n",
      " [ 0  0  0  0  0  0]] \n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.69      0.83      0.76        78\n",
      "           2       0.58      0.65      0.61        66\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       0.50      0.41      0.45        22\n",
      "\n",
      "    accuracy                           0.63       187\n",
      "   macro avg       0.35      0.38      0.36       187\n",
      "weighted avg       0.55      0.63      0.59       187\n",
      "\n",
      "====================================TCGA\n",
      "=== Slide-level Evaluation ===\n",
      "Slides with NaN predictions: 0 / 316\n",
      "\n",
      "--- Including NaNs (as class 5) ---\n",
      "Accuracy: 0.4810126582278481\n",
      "--- Excluding NaNs ---\n",
      "Accuracy: 0.4810126582278481\n",
      "Balanced accuracy: 0.3682093034729024\n",
      "Confusion matrix:\n",
      " [[ 0 20  5  0  0  0]\n",
      " [ 0 62 33  1  2  0]\n",
      " [ 0 10 61  1  1  0]\n",
      " [ 0  1 30  2  1  0]\n",
      " [ 0  1 56  2 27  0]\n",
      " [ 0  0  0  0  0  0]] \n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.66      0.63      0.65        98\n",
      "           2       0.33      0.84      0.47        73\n",
      "           3       0.33      0.06      0.10        34\n",
      "           4       0.87      0.31      0.46        86\n",
      "\n",
      "    accuracy                           0.48       316\n",
      "   macro avg       0.44      0.37      0.34       316\n",
      "weighted avg       0.55      0.48      0.45       316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ntu/lizh0106/.conda/envs/trident/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/users/ntu/lizh0106/.conda/envs/trident/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/users/ntu/lizh0106/.conda/envs/trident/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/users/ntu/lizh0106/.conda/envs/trident/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/users/ntu/lizh0106/.conda/envs/trident/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/users/ntu/lizh0106/.conda/envs/trident/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nan_count': 0,\n",
       " 'acc_all': 0.4810126582278481,\n",
       " 'confusion_matrix_all': array([[ 0, 20,  5,  0,  0,  0],\n",
       "        [ 0, 62, 33,  1,  2,  0],\n",
       "        [ 0, 10, 61,  1,  1,  0],\n",
       "        [ 0,  1, 30,  2,  1,  0],\n",
       "        [ 0,  1, 56,  2, 27,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0]]),\n",
       " 'acc_valid': 0.4810126582278481,\n",
       " 'balanced_acc_valid': 0.3682093034729024,\n",
       " 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00        25\\n           1       0.66      0.63      0.65        98\\n           2       0.33      0.84      0.47        73\\n           3       0.33      0.06      0.10        34\\n           4       0.87      0.31      0.46        86\\n\\n    accuracy                           0.48       316\\n   macro avg       0.44      0.37      0.34       316\\nweighted avg       0.55      0.48      0.45       316\\n'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggc_index_p = df_aggc_index\n",
    "df_tcga_index_p = df_tcga_index\n",
    "\n",
    "aggc_prob_p = base_path / test_folder / aggc_prob_p\n",
    "tcga_prob_p = base_path / test_folder / tcga_prob_p\n",
    "\n",
    "df_aggc = pd.read_csv(df_aggc_index_p)\n",
    "df_tcga = pd.read_csv(df_tcga_index_p)\n",
    "\n",
    "aggc_tile_proba = np.load(aggc_prob_p)   # shape: (n_tiles, n_classes>=3)\n",
    "tcga_tile_proba = np.load(tcga_prob_p)\n",
    "\n",
    "# 先试最稳的：weight（不删tile）\n",
    "pred_df_aggc = agg_from_tiles(\n",
    "    df_aggc, aggc_tile_proba,\n",
    "    agg_input=\"proba\",\n",
    "    conf_mode=\"threshold\",\n",
    "    weight_power=5.0,    # 你可以试 1.0 / 2.0 / 3.0\n",
    "    conf_threshold = 0.5,\n",
    "    min_tiles=5\n",
    ")\n",
    "\n",
    "pred_df_tcga = agg_from_tiles(\n",
    "    df_tcga, tcga_tile_proba,\n",
    "    agg_input=\"proba\",\n",
    "    conf_mode=\"threshold\",\n",
    "    weight_power=5.0,\n",
    "    conf_threshold = 0.5,\n",
    "    min_tiles=5\n",
    ")\n",
    "\n",
    "##############################\n",
    "\n",
    "evaluate_slide_predictions(pred_df_aggc,df_aggc,\n",
    "    pred_col=\"ISUP_grade_group\",true_col=\"y\",treat_nan_as_class=5,verbose=True,)\n",
    "\n",
    "print(\"====================================TCGA\")\n",
    "\n",
    "evaluate_slide_predictions(pred_df_tcga,df_tcga,\n",
    "    pred_col=\"ISUP_grade_group\",true_col=\"y\",treat_nan_as_class=5,verbose=True,)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
